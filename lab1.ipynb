{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Q5lzpQrIl2UL"
      },
      "source": [
        "# Lab1 - Scikit-learn\n",
        "Author: *Samuel Sofela*\n",
        "\n",
        "## 1. Introduction\n",
        "\n",
        "The goal of this lab is to become familiar with the scikit-learn library.\n",
        "\n",
        "You will practice loading example datasets, perform classification and regression with linear scikit-learn models, and investigate the effects of reducing the number of features (columns in X) and the number of samples (rows in X and y).\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "GyDhYsyXl2UM"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "oXeOQtGZl2UM"
      },
      "source": [
        "## 2. Classification\n",
        "\n",
        "Using yellowbrick spam - classification  \n",
        "https://www.scikit-yb.org/en/latest/api/datasets/spam.html\n",
        "\n",
        "The goal is to investigate `LogisticRegression(max_iter=2000)` and effects of reducing the number of features and number of samples on classification performance."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6Nvc1EBml2UM"
      },
      "source": [
        "### 2.1 Implement convenience function"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BaOhivSvl2UM"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "def get_classifier_accuracy(model, X, y):\n",
        "    '''Calculate train and validation accuracy of classifier (model)\n",
        "        \n",
        "        Splits feature matrix X and target vector y \n",
        "        with sklearn train_test_split() and random_state=956.\n",
        "        \n",
        "        model (sklearn classifier): Classifier to train and evaluate\n",
        "        X (numpy.array or pandas.DataFrame): Feature matrix\n",
        "        y (numpy.array or pandas.Series): Target vector\n",
        "        \n",
        "        returns: training accuracy, validation accuracy\n",
        "    \n",
        "    '''\n",
        "    \n",
        "    #TODO: IMPLEMENT FUNCTION BODY\n",
        "    "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "yY1xx51Pl2UN"
      },
      "source": [
        "### 2.2 Load data\n",
        "\n",
        "Use the yellowbrick function `load_spam()`, load the spam data set into feature matrix `X` and target vector `y`.\n",
        "\n",
        "Print size and type of `X` and `y`.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RaDaq_kkl2UN",
        "outputId": "1fb54356-a1b2-4b76-dde8-cb81780f027a"
      },
      "outputs": [
        {
          "ename": "DatasetsError",
          "evalue": "the downloaded dataset was improperly packaged without meta.json - please report this bug to the Yellowbrick maintainers!",
          "output_type": "error",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mDatasetsError\u001b[0m                             Traceback (most recent call last)",
            "\u001b[0;32m/var/folders/18/yxv48zsx08s_dbth29rh3g2r0000gn/T/ipykernel_18325/990102409.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0myellowbrick\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdatasets\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloaders\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mload_spam\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;31m#dataset = load_spam(return_dataset=True)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mload_spam\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0;31m#dataset.to_dataframe()\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m~/opt/anaconda3/envs/ensf-ml1/lib/python3.8/site-packages/yellowbrick/datasets/loaders.py\u001b[0m in \u001b[0;36mload_spam\u001b[0;34m(data_home, return_dataset)\u001b[0m\n\u001b[1;32m    433\u001b[0m         \u001b[0mdata\u001b[0m \u001b[0;32min\u001b[0m \u001b[0ma\u001b[0m \u001b[0mvariety\u001b[0m \u001b[0mof\u001b[0m \u001b[0mformats\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mwell\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0massociated\u001b[0m \u001b[0mmetadata\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mcontent\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    434\u001b[0m     \"\"\"\n\u001b[0;32m--> 435\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_load_dataset\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"spam\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdata_home\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreturn_dataset\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    436\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    437\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m~/opt/anaconda3/envs/ensf-ml1/lib/python3.8/site-packages/yellowbrick/datasets/loaders.py\u001b[0m in \u001b[0;36m_load_dataset\u001b[0;34m(name, data_home, return_dataset)\u001b[0m\n\u001b[1;32m     60\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mreturn_dataset\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     61\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 62\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_data\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     63\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     64\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m~/opt/anaconda3/envs/ensf-ml1/lib/python3.8/site-packages/yellowbrick/datasets/base.py\u001b[0m in \u001b[0;36mto_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    175\u001b[0m         \"\"\"\n\u001b[1;32m    176\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mpd\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 177\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_pandas\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    178\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mto_numpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    179\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m~/opt/anaconda3/envs/ensf-ml1/lib/python3.8/site-packages/yellowbrick/datasets/base.py\u001b[0m in \u001b[0;36mto_pandas\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    218\u001b[0m         \u001b[0;31m# Ensure the metadata is valid before continuing\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    219\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmeta\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 220\u001b[0;31m             raise DatasetsError(\n\u001b[0m\u001b[1;32m    221\u001b[0m                 (\n\u001b[1;32m    222\u001b[0m                     \u001b[0;34m\"the downloaded dataset was improperly packaged without meta.json \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mDatasetsError\u001b[0m: the downloaded dataset was improperly packaged without meta.json - please report this bug to the Yellowbrick maintainers!"
          ]
        }
      ],
      "source": [
        "# TODO: ADD YOUR CODE HERE\n",
        "from yellowbrick.datasets.loaders import load_spam\n",
        "#dataset = load_spam(return_dataset=True)\n",
        "X,y = load_spam()\n",
        "#dataset.to_dataframe()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9s_jb91Al2UN"
      },
      "source": [
        "Using the sklearn function `train_test_split()` prepare a feature matrix `X_small` and target vector `y_small` that contain only **1%** of the rows. Use `random_state=174`.\n",
        "\n",
        "Print size and type of `X_small` and `y_small`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VUgXNQjIl2UO"
      },
      "outputs": [],
      "source": [
        "# TODO: ADD YOUR CODE HERE\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ck3hhlBZl2UO"
      },
      "source": [
        "### 2.3 Train and evaluate models\n",
        "\n",
        "1. Import `LogisticRegression` from sklearn\n",
        "2. Instantiate model `LogisticRegression(max_iter=2000)`.\n",
        "3. Create a pandas DataFrame `results` with columns: Data size, training accuracy, validation accuracy\n",
        "4. Call your convenience function `get_classifier_accuracy()` using \n",
        "    - `X` and `y`\n",
        "    - Only first two columns of `X` and `y`\n",
        "    - `X_small` and `y_small`\n",
        "5. Add the data size, training and validation accuracy for each call to the `results` DataFrame\n",
        "6. Print `results`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VUVoZBnHl2UO"
      },
      "outputs": [],
      "source": [
        "# TODO: ADD YOUR CODE HERE\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "LeEvyxrQl2UO"
      },
      "source": [
        "### 2.4 Questions\n",
        "1. What is the validation accuracy using all data? What is the difference between training and validation accuracy?\n",
        "1. How does the validation accuracy and difference between training and validation change when only two columns are used? Provide values.\n",
        "1. How does the validation accuracy and difference between training and validation change when only 1% of the rows are used? Provide values.\n",
        "\n",
        "*YOUR ANSWERS HERE*\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "hAzUq6NMl2UO"
      },
      "source": [
        "## 3. Regression\n",
        "\n",
        "Using yellowbrick energy - regression  \n",
        "https://www.scikit-yb.org/en/latest/api/datasets/energy.html\n",
        "\n",
        "The goal is to investigate `LinearRegression()` and effects of reducing the number of features and number of samples on regression performance."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xaHmBrSSl2UP"
      },
      "source": [
        "### 3.1 Implement convenience function"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "z5N9Hfdll2UP"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics import mean_squared_error\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "def get_regressor_mse(model, X, y):\n",
        "    '''Calculate train and validation mean-squared error (mse) of regressor (model)\n",
        "        \n",
        "        Splits feature matrix X and target vector y \n",
        "        with sklearn train_test_split() and random_state=956.\n",
        "        \n",
        "        model (sklearn regressor): Regressor to train and evaluate\n",
        "        X (numpy.array or pandas.DataFrame): Feature matrix\n",
        "        y (numpy.array or pandas.Series): Target vector\n",
        "        \n",
        "        returns: training mse, validation mse\n",
        "    \n",
        "    '''\n",
        "   \n",
        "    #TODO: IMPLEMENT FUNCTION BODY\n",
        "    "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "L3uYNi_4l2UP"
      },
      "source": [
        "### 3.2 Load data\n",
        "\n",
        "Use the yellowbrick function `load_energy()` load the energy data set into feature matrix `X` and target vector `y`.\n",
        "\n",
        "Print dimensions and type of `X` and `y`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3_9dJGhVl2UP"
      },
      "outputs": [],
      "source": [
        "# TODO: ADD YOUR CODE HERE\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Kgqzap7ql2UP"
      },
      "source": [
        "Using the sklearn function `train_test_split()` prepare a feature matrix `X_small` and target vector `y_small` that contain only **1%** of the rows. Use `random_state=174`.\n",
        "\n",
        "Print size and type of `X_small` and `y_small`."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "9ezYd1VZl2UP"
      },
      "outputs": [],
      "source": [
        "# TODO: ADD YOUR CODE HERE\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "klLF62Nol2UP"
      },
      "source": [
        "### 3.3 Train and evaluate models\n",
        "\n",
        "1. Import `LinearRegression` from sklearn\n",
        "2. Instantiate model `LinearRegression()`.\n",
        "3. Create a pandas DataFrame `results` with columns: Data size, training MSE, validation MSE\n",
        "4. Call your convenience function `get_regressor_mse()` using \n",
        "    - `X` and `y`\n",
        "    - Only first two columns of `X` and `y`\n",
        "    - `X_small` and `y_small`\n",
        "5. Add the data size, training and validation MSE for each call to the `results` DataFrame\n",
        "6. Print `results`"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JzlJ_tKUl2UP"
      },
      "outputs": [],
      "source": [
        "# TODO: ADD YOUR CODE HERE\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OFRkx5ifl2UP"
      },
      "source": [
        "### 3.4 Questions\n",
        "1. What is the validation MSE using all data? What is the difference between training and validation MSE?\n",
        "1. How does the validation MSE and difference between training and validation change when only two columns are used? Provide values.\n",
        "1. How does the validation MSE and difference between training and validation change when only 1% of the rows are used? Provide values.\n",
        "\n",
        "*YOUR ANSWERS HERE*\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "se5XzVhVl2UQ"
      },
      "source": [
        "## 4. Observations/Interpretation\n",
        "\n",
        "Describe any pattern you see in the results. Relate your findings to what we discussed during lectures. Include data to justify your findings.\n",
        "\n",
        "\n",
        "*ADD YOUR FINDINGS HERE*\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dOoC15GZl2UQ"
      },
      "source": [
        "## 5. Reflection\n",
        "Include a sentence or two about:\n",
        "- what you liked or disliked,\n",
        "- found interesting, confusing, challangeing, motivating\n",
        "while working on this assignment.\n",
        "\n",
        "\n",
        "*ADD YOUR THOUGHTS HERE*\n",
        "\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.13"
    },
    "colab": {
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}